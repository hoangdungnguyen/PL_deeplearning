{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dropoutNN+PL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoangdungnguyen/PL_deeplearning/blob/master/dropoutNN%2BPL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM9Ss1TPOLmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "mnist = input_data.read_data_sets(\"\", one_hot=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Asrl80IK22fL",
        "colab_type": "code",
        "outputId": "aa3fbc1a-1326-4524-ef5d-47564e9905e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "stratSplit = StratifiedShuffleSplit(test_size=100, random_state=2812, n_splits=1)\n",
        "stratSplit.get_n_splits(mnist.train.images, np.argmax(mnist.train.labels, axis = 1))\n",
        "for train_index, test_index in stratSplit.split(X = mnist.train.images,y = mnist.train.labels):\n",
        "  x_train = mnist.train.images[test_index]\n",
        "  y_train = mnist.train.labels[test_index]\n",
        "  x_PL = mnist.train.images[train_index]\n",
        "\n",
        "print('Labeled data size :', x_train.shape)\n",
        "print('Unlabeled data size :', x_PL.shape)\n",
        "print('Proportion of class label in train data: ')\n",
        "pd.DataFrame(np.unique(np.argmax(y_train,1), return_counts = True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labeled data size : (100, 784)\n",
            "Unlabeled data size : (54900, 784)\n",
            "Proportion of class label in train data: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0   1   2   3   4  5   6   7   8   9\n",
              "0   0   1   2   3   4  5   6   7   8   9\n",
              "1  10  11  10  10  10  9  10  10  10  10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-f4BgzeOg_n",
        "colab_type": "code",
        "outputId": "421eed7c-b690-434c-959c-392adf29614d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.test.is_gpu_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n04njpWsPKeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Define hyper-parameters #####\n",
        "\n",
        "# Dropout parameters\n",
        "dropoutRate_0 = 0.\n",
        "dropoutRate_1 = 0.5 #ref\n",
        "\n",
        "# NN parameters\n",
        "inputN = 784 #default\n",
        "hiddenN = 5000 #ref \n",
        "outputN = 10 #default\n",
        "\n",
        "# DAE_NN parameters\n",
        "DAE_hiddenN1 = 256 # ref\n",
        "DAE_hiddenN2 = 128\n",
        "DAE_hiddenN3 = 256\n",
        "destruction_proportion = 0.5 # ref\n",
        "trainingEpochsDAE = 50\n",
        "batch_sizeDAE = 256\n",
        "\n",
        "# iteraction parameters\n",
        "trainingEpochs = 3000 #ref\n",
        "batchSize = 32 # ref\n",
        "PLbatchSize = 256 #ref\n",
        "\n",
        "# balancing coefficient\n",
        "T1 = 100 #ref\n",
        "T2 = 600 #ref\n",
        "a = 0. #ref\n",
        "af = 3. #ref\n",
        "\n",
        "T1_DAE = 200 #ref\n",
        "T2_DAE = 800 #ref\n",
        "\n",
        "# SGD with dynamic momentum\n",
        "learningRate = 1.5 # ref\n",
        "T = 500 #ref\n",
        "k = 0.998 #ref\n",
        "pi = 0.5 #ref\n",
        "pf = 0.99 #ref\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rndsoUSePQgv",
        "colab_type": "code",
        "outputId": "9ebd63e4-ef19-4c65-f350-4028b409f85c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "##### Define NN architecture ####\n",
        "\n",
        "x = tf.placeholder(\"float\", [None, inputN])\n",
        "y = tf.placeholder(\"float\", [None, outputN])\n",
        "PLx = tf.placeholder(\"float\", [None, inputN])\n",
        "PLy = tf.placeholder(\"float\", [None, outputN])\n",
        "DAE_x = tf.placeholder(\"float\", [None, inputN])\n",
        "DAE_x_noise = tf.placeholder(\"float\", [None, inputN])\n",
        "alpha_t = tf.placeholder(\"float\", )\n",
        "p_t = tf.placeholder(\"float\",)\n",
        "epsilon_t = tf.placeholder(\"float\",)\n",
        "plt.clf()\n",
        "\n",
        "def NN(x, w, b):\n",
        "    # Hidden layer 1\n",
        "    HL = tf.add(tf.matmul(x, w['h1']), b['b1'])\n",
        "    HL = tf.nn.relu(HL)\n",
        "    HL = tf.nn.dropout(HL, rate = dropoutRate_1)\n",
        "    # Output layer\n",
        "    out_layer =tf.matmul(HL, w['out']) + b['out']\n",
        "\n",
        "    return out_layer\n",
        "\n",
        "def DAE_NN(DAE_x_noise, w, b):\n",
        "  # Hidden layer 1\n",
        "  HL1 = tf.nn.sigmoid(tf.add(tf.matmul(DAE_x_noise, w['h1']), b['b1']))\n",
        "  #HL1 = tf.nn.dropout(HL1, rate = dropoutRate_1)\n",
        "  # Hidden layer 2\n",
        "  HL2 = tf.nn.sigmoid(tf.add(tf.matmul(HL1, w['h2']), b['b2']))\n",
        "  #HL2 = tf.nn.dropout(HL2, rate = dropoutRate_1)\n",
        "  # Hidden layer 3\n",
        "  HL3 = tf.nn.sigmoid(tf.add(tf.matmul(HL2, w['h3']), b['b3']))\n",
        "  #HL3 = tf.nn.dropout(HL3, rate = dropoutRate_1)\n",
        "  # Output layer\n",
        "  out_layer = tf.nn.sigmoid(tf.add(tf.matmul(HL3, w['out']), b['out']))\n",
        "  \n",
        "  return out_layer\n",
        "\n",
        "\n",
        "# initialize weights and biases\n",
        "with tf.variable_scope('NN') :\n",
        "  weightsNN = {\n",
        "    'h1': tf.Variable(tf.random_normal([inputN, hiddenN])),\n",
        "    'out': tf.Variable(tf.random_normal([hiddenN, outputN]))\n",
        "    }\n",
        "\n",
        "  biasesNN = {\n",
        "    'b1': tf.Variable(tf.random_normal([hiddenN])),\n",
        "    'out': tf.Variable(tf.random_normal([outputN]))\n",
        "    }\n",
        "\n",
        "with tf.variable_scope('PL') :\n",
        "  weightsPL = {\n",
        "    'h1': tf.Variable(tf.random_normal([inputN, hiddenN])),\n",
        "    'out': tf.Variable(tf.random_normal([hiddenN, outputN]))\n",
        "    }\n",
        "  biasesPL = {\n",
        "    'b1': tf.Variable(tf.random_normal([hiddenN])),\n",
        "    'out': tf.Variable(tf.random_normal([outputN]))\n",
        "    }\n",
        "\n",
        "with tf.variable_scope('DAE') :\n",
        "  weightsDAE = {\n",
        "    'h1': tf.Variable(tf.random_normal([inputN, DAE_hiddenN1])),\n",
        "    'h2': tf.Variable(tf.random_normal([DAE_hiddenN1, DAE_hiddenN2])),\n",
        "    'h3': tf.Variable(tf.random_normal([DAE_hiddenN2, DAE_hiddenN3])),\n",
        "    'out': tf.Variable(tf.random_normal([DAE_hiddenN3, inputN]))\n",
        "    }\n",
        "  biasesDAE = {\n",
        "    'b1': tf.Variable(tf.random_normal([DAE_hiddenN1])),\n",
        "    'b2': tf.Variable(tf.random_normal([DAE_hiddenN2])),\n",
        "    'b3': tf.Variable(tf.random_normal([DAE_hiddenN3])),\n",
        "    'out': tf.Variable(tf.random_normal([inputN]))\n",
        "    }\n",
        "\n",
        "predDAE = DAE_NN(DAE_x_noise, weightsDAE, biasesDAE)\n",
        "\n",
        "costDAE = tf.reduce_mean(tf.compat.v1.losses.log_loss(DAE_x, predDAE))\n",
        "\n",
        "predNN = NN(x, weightsNN, biasesNN)\n",
        "predPL = NN(x, weightsPL, biasesPL)\n",
        "predPL1 = NN(PLx, weightsPL, biasesPL)\n",
        "\n",
        "costNN = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=predNN,\n",
        "                                                                labels=y))\n",
        "\n",
        "costPL = tf.add(tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=predPL,\n",
        "                                                                       labels=y)),\n",
        "                (alpha_t * tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=predPL1,\n",
        "                                                                                labels=PLy))))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIfay6Tfvw44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Define optimizer #####\n",
        "\n",
        "optimizerNN = tf.train.MomentumOptimizer(learning_rate = (1-p_t)*epsilon_t,\n",
        "                                        momentum = -p_t/(1-p_t)).minimize(costNN)\n",
        "optimizerPL = tf.train.MomentumOptimizer(learning_rate = (1-p_t)*epsilon_t,\n",
        "                                        momentum = -p_t/(1-p_t)).minimize(costNN)\n",
        "\n",
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfDjGzIan4Ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Define benchmark functions #####\n",
        "\n",
        "def accuracytestNN():\n",
        "    # Test model\n",
        "    correct_prediction = tf.equal(tf.argmax(predNN, 1), tf.argmax(y, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "    # To keep sizes compatible with model\n",
        "    return accuracy.eval({x: mnist.test.images, y: mnist.test.labels})\n",
        "\n",
        "\n",
        "def accuracytestPL():\n",
        "    # Test model\n",
        "    correct_prediction = tf.equal(tf.argmax(predPL, 1), tf.argmax(y, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "    # To keep sizes compatible with model\n",
        "    return accuracy.eval({x: mnist.test.images, y: mnist.test.labels})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fAOV-ggPTJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dropNN_PL():\n",
        "  ### Neural Network parameters\n",
        "  iteration_list = []\n",
        "  neural_network_accuracy_list = []\n",
        "  pseudo_label_accuarcy_list = []\n",
        "  neural_network_accuracy = 0\n",
        "  pseudo_label_accuarcy = 0\n",
        "  iteration = 0\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    begin=time.time()\n",
        "    # Training cycle\n",
        "    for epoch in range(trainingEpochs):\n",
        "        avg_costNN = 0.\n",
        "        avg_costPL = 0.\n",
        "        total_batch = int(100 / batchSize)\n",
        "        # Loop over all batches\n",
        "        index = np.arange(x_train.shape[0])\n",
        "        np.random.shuffle(index)\n",
        "        batches_X = np.array_split(x_train[index], total_batch)\n",
        "        batches_y = np.array_split(y_train[index], total_batch)\n",
        "        index = np.arange(x_PL.shape[0])\n",
        "        np.random.shuffle(index)\n",
        "        batches_X_PL = np.array_split(x_PL[index], total_batch)\n",
        "        for i in range(total_batch):\n",
        "            batch_x, batch_y = batches_X[i], batches_y[i]\n",
        "            if epoch > T:\n",
        "              p = pf\n",
        "            else:\n",
        "              p = epoch/T*pf + (1-epoch/T)*pi\n",
        "\n",
        "            _, cNN = sess.run([optimizerNN, costNN], feed_dict={x: batch_x,\n",
        "                                                                y: batch_y,\n",
        "                                                                p_t : p,\n",
        "                                                                epsilon_t : learningRate*(k**epoch)\n",
        "                                                                })\n",
        "            if epoch < T1:\n",
        "                a = 0\n",
        "            elif epoch < T2:\n",
        "                a = ((epoch - T1) / (T2 - T1)) * af\n",
        "            else :\n",
        "                a = af\n",
        "            \n",
        "\n",
        "            # Pseudolabel\n",
        "            batch_xpred = batches_X_PL[i]\n",
        "            batch_ypred = sess.run([predPL], feed_dict={x: batch_xpred})\n",
        "            batch_ypred = batch_ypred[0]\n",
        "            batch_ypred = batch_ypred.argmax(1)\n",
        "            batch_ypre = np.zeros((batch_xpred.shape[0], 10))\n",
        "            for ii in range(PLbatchSize):\n",
        "                batch_ypre[ii, batch_ypred[ii]] = 1\n",
        "\n",
        "            _, cPL = sess.run([optimizerPL, costPL], feed_dict={x: batch_x,\n",
        "                                                                y: batch_y,\n",
        "                                                                PLx: batch_xpred,\n",
        "                                                                PLy: batch_ypre,\n",
        "                                                                p_t : p,\n",
        "                                                                epsilon_t : learningRate*(k**epoch),\n",
        "                                                                alpha_t: a})\n",
        "            iteration += 1\n",
        "            # Compute average loss\n",
        "            avg_costNN += cNN / total_batch\n",
        "            avg_costPL += cPL / total_batch\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            neural_network_accuracy = accuracytestNN()\n",
        "            pseudo_label_accuarcy = accuracytestPL()\n",
        "            print(\"Epoch {} | time = {:.4f} | DropNN acc = {:.4f} | DropNN+PL acc = {:.4f} \"\n",
        "                  .format(epoch, time.time() - begin,\n",
        "                          neural_network_accuracy, pseudo_label_accuarcy))\n",
        "\n",
        "            iteration_list = np.append(iteration_list, iteration)\n",
        "            neural_network_accuracy_list = np.append(neural_network_accuracy_list, neural_network_accuracy)\n",
        "            pseudo_label_accuarcy_list = np.append(pseudo_label_accuarcy_list, pseudo_label_accuarcy)\n",
        "\n",
        "        plt.plot(iteration_list, pseudo_label_accuarcy_list, iteration_list, neural_network_accuracy_list, 'r--')\n",
        "    print(\"Optimization Finished!\")\n",
        "    print(\"Neural Network accuracy:\", accuracytestNN())\n",
        "    print(\"+PL:\", accuracytestPL())\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eZUTnBX8qrZ",
        "colab_type": "code",
        "outputId": "579c512d-d851-4c52-a0ac-fb9904429d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        }
      },
      "source": [
        "dropNN_PL()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 | time = 0.5472 | DropNN acc = 0.2174 | DropNN+PL acc = 0.1021 \n",
            "Epoch 100 | time = 31.0627 | DropNN acc = 0.0892 | DropNN+PL acc = 0.1047 \n",
            "Epoch 200 | time = 61.7149 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1021 \n",
            "Epoch 300 | time = 92.2135 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1018 \n",
            "Epoch 400 | time = 122.7676 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1100 \n",
            "Epoch 500 | time = 153.3870 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1067 \n",
            "Epoch 600 | time = 184.0832 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1032 \n",
            "Epoch 700 | time = 214.7156 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1080 \n",
            "Epoch 800 | time = 245.5348 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1025 \n",
            "Epoch 900 | time = 276.2127 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1061 \n",
            "Epoch 1000 | time = 306.9373 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1007 \n",
            "Epoch 1100 | time = 337.6623 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1068 \n",
            "Epoch 1200 | time = 368.4486 | DropNN acc = 0.0980 | DropNN+PL acc = 0.0973 \n",
            "Epoch 1300 | time = 399.1574 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1027 \n",
            "Epoch 1400 | time = 429.9437 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1065 \n",
            "Epoch 1500 | time = 460.7343 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1024 \n",
            "Epoch 1600 | time = 491.7391 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1005 \n",
            "Epoch 1700 | time = 522.5609 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1037 \n",
            "Epoch 1800 | time = 553.3496 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1062 \n",
            "Epoch 1900 | time = 584.1856 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1058 \n",
            "Epoch 2000 | time = 615.0577 | DropNN acc = 0.0980 | DropNN+PL acc = 0.0991 \n",
            "Epoch 2100 | time = 645.9558 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1074 \n",
            "Epoch 2200 | time = 676.8608 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1049 \n",
            "Epoch 2300 | time = 707.7546 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1048 \n",
            "Epoch 2400 | time = 738.7415 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1002 \n",
            "Epoch 2500 | time = 769.7084 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1077 \n",
            "Epoch 2600 | time = 800.9377 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1049 \n",
            "Epoch 2700 | time = 831.9168 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1037 \n",
            "Epoch 2800 | time = 862.9133 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1053 \n",
            "Epoch 2900 | time = 893.8942 | DropNN acc = 0.0980 | DropNN+PL acc = 0.1050 \n",
            "Optimization Finished!\n",
            "Neural Network accuracy: 0.098\n",
            "+PL: 0.1026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}